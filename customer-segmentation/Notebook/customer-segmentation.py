# -*- coding: utf-8 -*-
"""Customer-Segmentation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Pkvwbf9495b_E2JyH2ORtp3_O83ztYoZ
"""

import pandas as pd
import numpy as np
import datetime as dt
import pickle
import seaborn as sns
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

df = pd.read_excel("Online Retail.xlsx")

df.head()

df.shape

df.dtypes

df.isna().sum()

df = df.drop(['Description'], axis = 1)

df.head()

any(df['Quantity'] < 0)

df = df[df['Quantity'] > 0]

df = df.dropna(subset=['CustomerID'])

df.isna().sum()

df.shape

df['Total Price'] = df['Quantity'] * df['UnitPrice']

df.head()

df['InvoicDate'] = pd.to_datetime(df['InvoiceDate'])

df.head()

reference_date = df['InvoiceDate'].max() + dt.timedelta(days=1)
reference_date

rfm = df.groupby('CustomerID').agg({
    'InvoiceDate': lambda x: (reference_date - x.max()).days,  # Recency
    'InvoiceNo': 'nunique',                                   # Frequency
    'Total Price': 'sum'                                       # Monetary
}).reset_index()

rfm.columns = ['CustomerID', 'Recency', 'Frequency', 'Monetary']

rfm.head()

scaler = StandardScaler()
rfm_scaled = scaler.fit_transform(rfm[['Recency', 'Frequency', 'Monetary']])

rfm.shape

sse = []
for k in range(1, 11):
    kmeans = KMeans(n_clusters=k, random_state=23062005 )
    kmeans.fit(rfm_scaled)
    sse.append(kmeans.inertia_)

plt.plot(range(1, 11), sse, marker='o')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('SSE (Inertia)')
plt.title('Elbow Method for Optimal k')
plt.show()

kmeans = KMeans(n_clusters=4, random_state=42)
rfm['Cluster'] = kmeans.fit_predict(rfm_scaled)

cluster_counts = rfm['Cluster'].value_counts()
print(cluster_counts)

# Create a 3D scatter plot
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

# Plot points with different colors based on clusters
ax.scatter(rfm['Recency'], rfm['Frequency'], rfm['Monetary'], c=rfm['Cluster'], cmap='viridis')

ax.set_xlabel('Recency')
ax.set_ylabel('Frequency')
ax.set_zlabel('Monetary')
ax.set_title('3D Scatter Plot of Customer Segments')

plt.show()

plt.figure(figsize=(8, 6))
plt.scatter(rfm['Recency'], rfm['Frequency'], c=rfm['Cluster'], cmap='viridis')
plt.xlabel('Recency')
plt.ylabel('Frequency')
plt.title('Recency vs Frequency (Customer Segments)')
plt.colorbar(label='Cluster')
plt.show()

# Plot data points and cluster centers
plt.figure(figsize=(8, 6))
plt.scatter(rfm['Recency'], rfm['Frequency'], c=rfm['Cluster'], cmap='viridis')

# Plot the cluster centers
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=200, c='red', marker='X', label='Centroids')

plt.xlabel('Recency')
plt.ylabel('Frequency')
plt.title('Recency vs Frequency with Cluster Centers')
plt.legend()
plt.colorbar(label='Cluster')
plt.show()

cluster_counts = rfm['Cluster'].value_counts()

plt.figure(figsize=(8, 6))
cluster_counts.plot(kind='bar', color='skyblue')
plt.xlabel('Cluster')
plt.ylabel('Number of Customers')
plt.title('Cluster Distribution')
plt.show()

# Create a DataFrame of cluster centers
cluster_centers_df = pd.DataFrame(kmeans.cluster_centers_, columns=['Recency', 'Frequency', 'Monetary'])

# Plot the heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(cluster_centers_df, annot=True, cmap='coolwarm', cbar=True)
plt.title('Heatmap of Cluster Centers')
plt.show()

# Create a DataFrame to view the cluster centers (average RFM values)
cluster_centers_df = pd.DataFrame(kmeans.cluster_centers_, columns=['Recency', 'Frequency', 'Monetary'])
print(cluster_centers_df)

scaler = StandardScaler()
rfm_scaled = scaler.fit_transform(rfm[['Recency', 'Frequency', 'Monetary']])

cluster_centers_original = scaler.inverse_transform(kmeans.cluster_centers_)


cluster_centers_df_original = pd.DataFrame(cluster_centers_original, columns=['Recency', 'Frequency', 'Monetary'])
print(cluster_centers_df_original)

cluster_labels = {
    0: 'Loyal High Spend Customers',
    1: 'Inactive or Low Spend Customers',
    2: 'VIP High Frequency & High Spend',
    3: 'Moderately Engaged Customers'
}

rfm['Cluster_Label'] = rfm['Cluster'].map(cluster_labels)

rfm.head()

# Save the trained scaler
with open("scaler.pkl", "wb") as f:
    pickle.dump(scaler, f)
# Save the trained KMeans model
with open("kmeans_model.pkl", "wb") as f:
    pickle.dump(kmeans, f)