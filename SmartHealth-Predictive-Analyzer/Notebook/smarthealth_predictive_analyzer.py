# -*- coding: utf-8 -*-
"""SmartHealth-Predictive-Analyzer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gfWZYeD1jlxph12GgsVhLkgvmgdHTxBu
"""

import pandas as pd

df = pd.read_csv("diabetess.csv")

df.shape

df.head()

df.dtypes

df.isnull().sum()

df.duplicated().sum()

from scipy.stats import zscore

z_scores = zscore(df.select_dtypes(include=['float64', 'int64']))

outliers = (z_scores > 3).sum(axis=1)
print("Number of outliers:", outliers.sum())

df_clean = df[(z_scores < 3).all(axis=1)]
print(f"Data after removing outliers: {df_clean.shape}")

z_scores = zscore(df_clean.select_dtypes(include=['float64', 'int64']))

outliers = (z_scores > 3).sum(axis=1)
print("Number of outliers:", outliers.sum())

import seaborn as sns
import matplotlib.pyplot as plt

numerical_cols = df_clean.select_dtypes(include=['float64', 'int64']).columns
for col in numerical_cols:
    plt.figure(figsize=(6, 4))
    sns.boxplot(x=df_clean[col])
    plt.title(f"Boxplot for {col}")
    plt.show()

numerical_cols = df_clean.select_dtypes(include=['float64', 'int64']).columns
for col in numerical_cols:
    plt.figure(figsize=(6, 4))
    sns.histplot(df_clean[col], kde=True)
    plt.title(f'Distribution of {col}')
    plt.show()

correlation_matrix = df_clean.corr()

plt.figure(figsize=(10, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('\n Correlation Matrix\n')
plt.show()

X = df_clean.drop(['Outcome'], axis = 1)
Y = df_clean['Outcome']

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=23, test_size = 0.2)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled = scaler.transform(x_test)

from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(random_state=42)

param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

grid_search = GridSearchCV(estimator=rf, param_grid=param_grid,
                           cv=5, n_jobs=-1, verbose=1, scoring='accuracy')

grid_search.fit(x_train_scaled, y_train)

best_rf = grid_search.best_estimator_

print("Best parameters:", grid_search.best_params_)

y_pred_best = best_rf.predict(x_test_scaled)

print("Tuned Accuracy:", accuracy_score(y_test, y_pred_best))
print(classification_report(y_test, y_pred_best))

cm = confusion_matrix(y_test, y_pred_best)

plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',
            xticklabels=['Predicted 0', 'Predicted 1'],
            yticklabels=['Actual 0', 'Actual 1'])

plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix Tuned Random Forest')
plt.show()

from sklearn.linear_model import LogisticRegression

log_reg = LogisticRegression(random_state=42)
log_reg.fit(x_train_scaled, y_train)

y_pred_log = log_reg.predict(x_test_scaled)

print("Accuracy:", accuracy_score(y_test, y_pred_log))
print(classification_report(y_test, y_pred_log))

cm = confusion_matrix(y_test, y_pred_log)

plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',
            xticklabels=['Predicted 0', 'Predicted 1'],
            yticklabels=['Actual 0', 'Actual 1'])

plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix Logisitic Regression')
plt.show()